input {
  kafka {
    topics => ["unauthenticated.VES_MEASUREMENT_OUTPUT"]
    bootstrap_servers => "10.60.18.145:9092"
  }
}

filter {
  mutate {
    add_field => {
      "src" => "ves"
      "host_ip" => "onap.fandrieu"
    }
    rename => { "message" => "rawdata"}
  }
  ruby {
    # Convert the Logstash timestamp to a milliseconds timestamp integer
    # You can use whatever makes sense to you as long as the timestamp is a valid timestamp integer in milliseconds
    code => "event.set('timestamp', (event.get('@timestamp').to_f * 1000).to_i)"
  }
}

output {
  kafka {
    topic_id => "ves.avro"
    bootstrap_servers => "192.168.0.78:9092"
    value_serializer => "org.apache.kafka.common.serialization.ByteArraySerializer"
    codec => pnda-avro{
      schema_uri => "dataplatform-raw.avsc"
    }
  }
  stdout {
    codec => "json"
  }
}